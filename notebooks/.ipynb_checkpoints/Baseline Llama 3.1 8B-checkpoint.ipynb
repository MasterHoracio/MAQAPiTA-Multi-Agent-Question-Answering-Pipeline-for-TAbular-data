{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02985a68-271f-44b5-baf7-3e8e74808c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm.notebook')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utilities import Generator\n",
    "from utilities import promptGenerator\n",
    "\n",
    "from databench_eval import Evaluator\n",
    "from databench_eval.utils import load_qa, load_table\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2ed97-6f66-4cb9-8a36-60328937f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device     = torch.device(\"cuda:3\")  # Select GPU 3\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\" # \"google/gemma-3-4b-it\"\n",
    "gen        = Generator.Generator(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903130f-1ee0-4d1a-8f1d-a0779a2b4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dev = load_qa(lang=\"ES\", name=\"iberlef\", split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c4896-4473-4c29-bb47-1fc2b94bde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_responses(responses, save_path: str) -> None:\n",
    "    with open(save_path, \"w\") as f:\n",
    "        for response in responses:\n",
    "            f.write(str(response).replace(\"\\n\", \" \") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff785f1-ea16-4dea-9c5b-39e01705a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_postprocess(response: str, row: dict):\n",
    "    try:\n",
    "        df = load_table(row[\"dataset\"], lang=\"ES\")\n",
    "        \n",
    "        global ans\n",
    "        \n",
    "        lead = \"\"\"\n",
    "def answer(df):\n",
    "    return \"\"\"\n",
    "        \n",
    "        exec_string = (\n",
    "            lead\n",
    "            + response\n",
    "            + \"\\nans = answer(df)\"\n",
    "        )\n",
    "        \n",
    "        local_vars = {\"df\": df, \"pd\": pd, \"np\": np}\n",
    "        exec(exec_string, local_vars)\n",
    "\n",
    "        ans = local_vars[\"ans\"]\n",
    "        if isinstance(ans, pd.Series):\n",
    "            ans = ans.tolist()\n",
    "        elif isinstance(ans, pd.DataFrame):\n",
    "            ans = ans.iloc[:, 0].tolist()\n",
    "        return ans.split(\"\\n\")[0] if \"\\n\" in str(ans) else ans\n",
    "    except Exception as e:\n",
    "        return f\"__CODE_ERROR__: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673e42c-baf4-48b4-a1c6-5e24749cb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for instance in tqdm(qa_dev):\n",
    "    prompt_handler = promptGenerator.promptGenerator(instance, False)\n",
    "    prompt         = prompt_handler.build_full_prompt(prompt_handler.baselinePrompt(instance), \"baseline\")\n",
    "    code           = gen.getLLMOutput(prompt, 200, True, 0.8, 0.9)\n",
    "    \n",
    "    # RUN CODE\n",
    "    output_code    = example_postprocess(code, instance)\n",
    "    \n",
    "    responses.append([str(output_code)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3883a59-403e-4374-ae8b-1f46a692fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(qa=qa_dev)\n",
    "print(f\"DataBenchSPA accuracy is {evaluator.eval(responses)}\")\n",
    "save_responses(responses, \"predictions.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
