{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d85d5f6-3536-4049-94df-e4b22bd04759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm.notebook')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utilities import Generator\n",
    "from utilities import promptGenerator\n",
    "\n",
    "from databench_eval import Evaluator\n",
    "from databench_eval.utils import load_qa, load_table\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d3956a-ead8-4d90-89ca-c1dbdea6ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.62it/s]\n",
      "Device set to use cuda:3\n"
     ]
    }
   ],
   "source": [
    "device     = torch.device(\"cuda:3\")  # Select GPU 3\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\" # \"google/gemma-3-4b-it\"\n",
    "gen        = Generator.Generator(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bc91ca-e13d-4d0d-964b-c9f0150db2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dev = load_qa(lang=\"ES\", name=\"iberlef\", split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e503d859-ba20-4622-b170-c448e36081c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_responses(responses, save_path: str) -> None:\n",
    "    with open(save_path, \"w\") as f:\n",
    "        for response in responses:\n",
    "            f.write(str(response).replace(\"\\n\", \" \") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f798ed2-1bcd-438f-aa69-3d2d9148701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_postprocess(response: str, row: dict):\n",
    "    try:\n",
    "        df = load_table(row[\"dataset\"], lang=\"ES\")\n",
    "        \n",
    "        global ans\n",
    "        lead = \"\"\"\n",
    "def answer(df):\n",
    "    \"\"\"\n",
    "        exec_string = (\n",
    "            response\n",
    "            + \"\\nans = answer(df)\"\n",
    "        )\n",
    "        local_vars = {\"df\": df, \"pd\": pd, \"np\": np}\n",
    "        exec(exec_string, local_vars)\n",
    "\n",
    "        ans = local_vars[\"ans\"]\n",
    "        if isinstance(ans, pd.Series):\n",
    "            ans = ans.tolist()\n",
    "        elif isinstance(ans, pd.DataFrame):\n",
    "            ans = ans.iloc[:, 0].tolist()\n",
    "        return ans.split(\"\\n\")[0] if \"\\n\" in str(ans) else ans\n",
    "    except Exception as e:\n",
    "        return f\"__CODE_ERROR__: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93c3586-f5b4-4729-81bc-5c82eb77fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset                                       | 3/100 [01:10<35:26, 21.92s/it]\n",
      " 10%|██████████████                                                                                                                               | 10/100 [05:08<46:20, 30.89s/it]\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for instance in tqdm(qa_dev):\n",
    "    prompt_handler = promptGenerator.promptGenerator(instance, True)\n",
    "\n",
    "    # GET COLUMNS\n",
    "    prompt_columns = prompt_handler.build_full_prompt(prompt_handler.getColumns(), \"columns\")\n",
    "    columns        = gen.getLLMOutput(prompt_columns, 100, True, 0.7, 0.8)\n",
    "    prompt_handler.setReducedColumns(columns)\n",
    "    \n",
    "    # GET INSTRUCTIONS\n",
    "    prompt_instructions = prompt_handler.build_full_prompt(prompt_handler.getInstructions(columns), \"instructions\")\n",
    "    cot_instructions    = gen.getLLMOutput(prompt_instructions, 300, True, 0.7, 0.8)\n",
    "\n",
    "    # GET CODE\n",
    "    prompt_code = prompt_handler.build_full_prompt(prompt_handler.getCode(cot_instructions, columns), \"code\")\n",
    "    code        = gen.getLLMOutput(prompt_code, 300, True, 0.8, 0.9)\n",
    "\n",
    "    # RUN CODE\n",
    "    output_code = example_postprocess(code, instance)\n",
    "\n",
    "    # DEBUG CODE\n",
    "    if str(output_code).startswith(\"__CODE_ERROR__\"):\n",
    "        attempts = 1\n",
    "        while str(output_code).startswith(\"__CODE_ERROR__\") and attempts <= 2:\n",
    "            # GET \"FIXED\" CODE\n",
    "            prompt_fix_bug = prompt_handler.build_full_prompt(prompt_handler.getCorrectCode(cot_instructions, columns, code, output_code), \"code_correction\")\n",
    "            fixed_code     = gen.getLLMOutput(prompt_fix_bug, 400, True, 0.8, 0.9)\n",
    "            output_code    = example_postprocess(fixed_code, instance)\n",
    "            attempts += 1\n",
    "\n",
    "    responses.append([str(output_code)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acaf33e-4005-4b2b-bc93-59de8c0b473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████████████▏                                                                                                                          | 11/100 [00:00<00:00, 40542.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBenchSPA accuracy is 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(qa=qa_dev)\n",
    "print(f\"DataBenchSPA accuracy is {evaluator.eval(responses)}\")\n",
    "save_responses(responses, \"predictions.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
