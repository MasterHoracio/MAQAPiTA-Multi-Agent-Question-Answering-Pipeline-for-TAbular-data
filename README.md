# MAQAPiTA: Multi-Agent Question-Answering Pipeline for TAbular Data

**MAQAPiTA** is a **personal research project** focused on exploring the use of **small LLMs** to answer questions over **tabular data**.  
The dataset used for experimentation comes from the competition **PRESTA: Preguntas y Respuestas sobre Tablas en EspaÃ±ol**, available at:  
https://www.codabench.org/competitions/5538/

The core idea behind this project is the design of a **multi-agent pipeline** combined with a **program-aided approach**, where the LLMs not only generate reasoning steps but also produce executable Python code that is dynamically evaluated.

---

## ğŸ§© Pipeline Overview

The proposed pipeline uses **four agents**, each responsible for a specific stage of the reasoning and code-generation process.  
Below is the figure of the pipeline (located at `img/MAQAPiTA.png`):

![MAQAPiTA Pipeline](img/MAQAPiTA.png)

### ğŸ”¹ **Agent 1 â€” Column Selector**
Given a question **Qi**, this agent selects the **relevant table columns** needed to answer it.

### ğŸ”¹ **Agent 2 â€” High-Level Planner**
This agent produces the **sequence of reasoning steps** (a high-level algorithm) required to answer **Qi** based on the selected columns.

### ğŸ”¹ **Agent 3 â€” Code Generator**
Using the outputs of Agents 1 and 2, this agent generates **Python code** to answer **Qi**.  
It assumes the table is a **Pandas DataFrame** and must complete a function that returns the correct result.

### ğŸ”¹ **Agent 4 â€” Code Debugger**
If the generated code fails to compile, this agent attempts to **repair the code**.  
The system allows up to **k correction iterations**.  
If the code cannot be fixed, an **error** is recorded as the final answer for **Qi**.

---

## ğŸ§ª Baseline Approach

As a comparison, a **simpler baseline** is included.  
The baseline consists of a **single prompt** directing the LLM to complete a Python function that answers question **Qi**, without using multiple agents or intermediate planning steps.

---

## ğŸ“ Project Structure

```
MAQAPiTA/
â”‚
â”œâ”€â”€ img/
â”‚ â””â”€â”€ MAQAPiTA.png # Figure of the proposed multi-agent pipeline
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ *.ipynb # Notebooks used for debugging and development
â”‚
â”œâ”€â”€ output_results/
â”‚ â””â”€â”€ *.txt # Output answers from both the pipeline and the baseline
â”‚ # (each line corresponds to the answer for a question)
â”‚
â”œâ”€â”€ test_data/
â”‚ â””â”€â”€ *.csv # Test dataset from the PRESTA competition
â”‚
â”œâ”€â”€ utilities/
â”‚ â”œâ”€â”€ Generator.py # Module to execute and manage LLM outputs
â”‚ â”œâ”€â”€ promptGenerator.py # Dynamically generates prompts for all agents and baseline
â”‚ â””â”€â”€ examples.txt # Few-shot examples for prompt construction
â”‚
â”œâ”€â”€ maqapita.py # Main entry point to run the multi-agent pipeline
â””â”€â”€ baseline.py # Baseline method using a single LLM prompt
```

---

## âš™ï¸ Supported Models

Both the **pipeline** and the **baseline** currently support the following LLM families:

- **Llama 3**
- **Gemma 3**

---

## ğŸš€ How to Run

### ğŸ”§ Run the Multi-Agent Pipeline
```bash
python3 maqapita.py --model meta-llama/Meta-Llama-3.1-8B-Instruct
```

### ğŸ”§ Run the Baseline Approach
```bash
python3 baseline.py --model google/gemma-3-4b-it
```
---

## ğŸ“Œ Final Notes

This project explores the feasibility of using **small open-source LLMs** combined with **multi-agent** reasoning and **program-aided execution** to answer questions over tabular data.
It is still under active development, and future updates may include expanded model support and improved debugging strategies.

If you find this project useful or interesting, feel free to â­ star the repository!